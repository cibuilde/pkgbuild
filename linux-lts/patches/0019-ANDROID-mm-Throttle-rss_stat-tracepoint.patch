From 457ed7d99afc766a38602fd3b1a7e55bb95798eb Mon Sep 17 00:00:00 2001
From: Joel Fernandes <joelaf@google.com>
Date: Tue, 10 Dec 2019 10:45:34 -0500
Subject: [PATCH 19/53] ANDROID: mm: Throttle rss_stat tracepoint

Previously we were throttling rss_stat tracepoint by checking for 512KB
boundary cross over. We removed that because upstream suggested eBPF or
other ways. However right now, we don't have support for those. Let us
re introduce the patch to throttle and avoid large number of events
which are causing data loss.

[CPNOTE: 01/07/21] Lee: Pinged the bug - meant to be going upstream
[CPNOTE: 15/07/21] Lee: Still pending - check back again soon

Bug: 145972256

Change-Id: I4132133aa36163430069b3ca2f57443940fb90b3
Signed-off-by: Joel Fernandes <joelaf@google.com>
(cherry picked from commit b3ddf584b0d6042bb355969ec0f3fa6a2a6117f6)
---
 include/linux/mm.h |  9 +++++----
 mm/memory.c        | 16 ++++++++++++++--
 2 files changed, 19 insertions(+), 6 deletions(-)

diff --git a/include/linux/mm.h b/include/linux/mm.h
index 0380df4f068..2f73faf48c1 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -1937,27 +1937,28 @@ static inline unsigned long get_mm_counter(struct mm_struct *mm, int member)
 	return (unsigned long)val;
 }
 
-void mm_trace_rss_stat(struct mm_struct *mm, int member, long count);
+void mm_trace_rss_stat(struct mm_struct *mm, int member, long count,
+		       long value);
 
 static inline void add_mm_counter(struct mm_struct *mm, int member, long value)
 {
 	long count = atomic_long_add_return(value, &mm->rss_stat.count[member]);
 
-	mm_trace_rss_stat(mm, member, count);
+	mm_trace_rss_stat(mm, member, count, value);
 }
 
 static inline void inc_mm_counter(struct mm_struct *mm, int member)
 {
 	long count = atomic_long_inc_return(&mm->rss_stat.count[member]);
 
-	mm_trace_rss_stat(mm, member, count);
+	mm_trace_rss_stat(mm, member, count, 1);
 }
 
 static inline void dec_mm_counter(struct mm_struct *mm, int member)
 {
 	long count = atomic_long_dec_return(&mm->rss_stat.count[member]);
 
-	mm_trace_rss_stat(mm, member, count);
+	mm_trace_rss_stat(mm, member, count, -1);
 }
 
 /* Optimized variant when page is already known not to be PageAnon */
diff --git a/mm/memory.c b/mm/memory.c
index a4d0f744a45..26a294a8866 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -167,9 +167,21 @@ static int __init init_zero_pfn(void)
 }
 early_initcall(init_zero_pfn);
 
-void mm_trace_rss_stat(struct mm_struct *mm, int member, long count)
+/*
+ * Only trace rss_stat when there is a 512kb cross over.
+ * Smaller changes may be lost unless every small change is
+ * crossing into or returning to a 512kb boundary.
+ */
+#define TRACE_MM_COUNTER_THRESHOLD 128
+
+void mm_trace_rss_stat(struct mm_struct *mm, int member, long count,
+		       long value)
 {
-	trace_rss_stat(mm, member, count);
+	long thresh_mask = ~(TRACE_MM_COUNTER_THRESHOLD - 1);
+
+	/* Threshold roll-over, trace it */
+	if ((count & thresh_mask) != ((count - value) & thresh_mask))
+		trace_rss_stat(mm, member, count);
 }
 
 #if defined(SPLIT_RSS_COUNTING)
-- 
2.36.2

